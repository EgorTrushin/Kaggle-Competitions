{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc8301b-a887-4d58-afcd-f81b4f761a91",
   "metadata": {},
   "source": [
    "# ICR - Identifying Age-Related Conditions: Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a542e5-dc47-47fa-95d3-03084a520052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "import yaml\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d620a42-977c-4a07-abbc-b563a527021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(data_path):\n",
    "    \"\"\"Reads and returns all competition data.\"\"\"\n",
    "    train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "    test = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "    greeks = pd.read_csv(os.path.join(data_path, \"greeks.csv\"))\n",
    "    sub = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "    train = train.rename(columns={\"BD \": \"BD\", \"CD \": \"CD\", \"CW \": \"CW\", \"FD \": \"FD\"})\n",
    "    test = test.rename(columns={\"BD \": \"BD\", \"CD \": \"CD\", \"CW \": \"CW\", \"FD \": \"FD\"})\n",
    "    return train, test, greeks, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267860dd-ef7b-478c-930e-6d12d21707bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    \"\"\"Competition metric.\"\"\"\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    balanced_log_loss_score = (\n",
    "        -1.0 / nc[0] * (np.sum(np.where(y_true == 0, 1, 0) * np.log(1 - y_pred)))\n",
    "        - 1.0 / nc[1] * (np.sum(np.where(y_true != 0, 1, 0) * np.log(y_pred)))\n",
    "    ) / 2.0\n",
    "    return balanced_log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56eb5d50-ba5c-406c-8fbc-2e4a80c0685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_loss_weight(y_true):\n",
    "    \"\"\"Calculates weights for dataset.\"\"\"\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1 / (nc[0] / y_true.shape[0]), 1 / (nc[1] / y_true.shape[0])\n",
    "    return w0, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c403a2-858b-4ba9-be70-7b5c6a8b5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(x_train, y_train, x_valid, y_valid, categorical_features, cat_params):\n",
    "    \"\"\"catboost training.\"\"\"\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "\n",
    "    cat_train = Pool(\n",
    "        data=x_train,\n",
    "        label=y_train,\n",
    "        weight=y_train.map({0: train_w0, 1: train_w1}),\n",
    "        cat_features=categorical_features,\n",
    "    )\n",
    "    cat_valid = Pool(\n",
    "        data=x_valid,\n",
    "        label=y_valid,\n",
    "        weight=y_valid.map({0: valid_w0, 1: valid_w1}),\n",
    "        cat_features=categorical_features,\n",
    "    )\n",
    "\n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(cat_train, eval_set=[cat_valid], use_best_model=True)\n",
    "\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e19892-00e6-48a0-b104-ffa22640bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(\n",
    "    x_train, y_train, x_valid, y_valid, categorical_features, lgb_params, train_params\n",
    "):\n",
    "    \"\"\"LightGBM training.\"\"\"\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        weight=y_train.map({0: train_w0, 1: train_w1}),\n",
    "    )\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        x_valid,\n",
    "        y_valid,\n",
    "        weight=y_valid.map({0: valid_w0, 1: valid_w1}),\n",
    "    )\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=lgb_params,\n",
    "        train_set=lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        num_boost_round=train_params[\"num_boost_round\"],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(train_params[\"stopping_rounds\"], verbose=True),\n",
    "            lgb.log_evaluation(train_params[\"period\"]),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    valid_pred = model.predict(x_valid)\n",
    "\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d61c8de-42af-48a0-a609-009f1ade7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(x_train, y_train, x_valid, y_valid, categorical_features, xgb_params, train):\n",
    "    \"\"\"XGBoost training.\"\"\"\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    xgb_train = xgb.DMatrix(\n",
    "        data=x_train, label=y_train, weight=y_train.map({0: train_w0, 1: train_w1})\n",
    "    )\n",
    "    xgb_valid = xgb.DMatrix(\n",
    "        data=x_valid, label=y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1})\n",
    "    )\n",
    "    xgb_params[\"scale_pos_weight\"] = train_w1 / train_w0\n",
    "    model = xgb.train(\n",
    "        xgb_params, dtrain=xgb_train, evals=[(xgb_train, \"train\"), (xgb_valid, \"eval\")], **train\n",
    "    )\n",
    "\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid), iteration_range=(0, model.best_ntree_limit))\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e144d6-6784-4874-a80a-960821100aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(config_path):\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as file_obj:\n",
    "        config = yaml.safe_load(file_obj)\n",
    "\n",
    "    #print(config_path)\n",
    "    #pprint(config)\n",
    "\n",
    "    df_train, _, df_greeks, _ = get_dataframes(config[\"data_path\"])\n",
    "\n",
    "    cat_features = [\"EJ\"]\n",
    "    num_features = list(df_train.columns)[1:-1]\n",
    "    num_features.remove(\"EJ\")\n",
    "    features = num_features + cat_features\n",
    "\n",
    "    str2int_dict = {}\n",
    "    str2int_dict[\"EJ\"] = {\"A\": 1, \"B\": 0}\n",
    "    df_train[\"EJ\"] = df_train[\"EJ\"].map(str2int_dict[\"EJ\"])\n",
    "    if config[\"denoise\"]:\n",
    "        df_train[num_features] = df_train[num_features].apply(lambda i: np.floor(i * 10))\n",
    "    if config[\"scaler\"] == \"RobustScaler\":\n",
    "        scaler = StandardScaler()\n",
    "        df_train[num_features] = scaler.fit_transform(df_train[num_features])\n",
    "\n",
    "    os.makedirs(config[\"models_path\"], exist_ok=True)\n",
    "    shutil.copy(config_path, os.path.join(config[\"models_path\"], \"config.yaml\"))\n",
    "\n",
    "    gc.enable()\n",
    "\n",
    "    print(f\"\\nTraining {config['method']} model\")\n",
    "\n",
    "    fold_scores = []\n",
    "    fold_scores_ = []\n",
    "    oof_preds = np.zeros(len(df_train))\n",
    "    oof_fold = np.zeros(len(df_train))\n",
    "\n",
    "    kfold = MultilabelStratifiedKFold(**config[\"folds\"])\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(df_train, df_greeks.iloc[:, 1:-1])):\n",
    "        print(\"\")\n",
    "\n",
    "        df_train_inner = df_train.iloc[train_idx]\n",
    "        df_greeks_inner = df_greeks.iloc[train_idx]\n",
    "        x_valid_outer = df_train[features].iloc[valid_idx]\n",
    "        y_valid_outer = df_train[\"Class\"].iloc[valid_idx]\n",
    "\n",
    "        fold_inner_scores = []\n",
    "        oof_inner_preds = np.zeros(len(df_train_inner))\n",
    "        oof_inner_fold = np.zeros(len(df_train_inner))\n",
    "  \n",
    "        models = []\n",
    "\n",
    "        kfold_inner = MultilabelStratifiedKFold(**config[\"folds\"])\n",
    "        for fold_inner, (train_idx_inner, valid_idx_inner) in enumerate(kfold_inner.split(df_train_inner, df_greeks_inner.iloc[:, 1:-1])):\n",
    "            # print(f\"\\n Outer Fold {fold + 1} Inner Fold {fold_inner + 1}\", flush=True)\n",
    " \n",
    "            x_train = df_train_inner[features].iloc[train_idx_inner]\n",
    "            y_train = df_train_inner[\"Class\"].iloc[train_idx_inner]\n",
    "            x_valid = df_train_inner[features].iloc[valid_idx_inner]\n",
    "            y_valid = df_train_inner[\"Class\"].iloc[valid_idx_inner] \n",
    "    \n",
    "            if config[\"method\"] == \"catboost\":\n",
    "                model, valid_pred = train_catboost(\n",
    "                    x_train, y_train, x_valid, y_valid, cat_features, config[\"model\"]\n",
    "                )\n",
    "            if config[\"method\"] == \"lightgbm\":\n",
    "                model, valid_pred = train_lightgbm(\n",
    "                    x_train, y_train, x_valid, y_valid, cat_features, config[\"model\"], config[\"train\"]\n",
    "                )\n",
    "            if config[\"method\"] == \"xgboost\":\n",
    "                model, valid_pred = train_xgboost(\n",
    "                    x_train, y_train, x_valid, y_valid, cat_features, config[\"model\"], config[\"train\"]\n",
    "                )\n",
    "\n",
    "            oof_inner_preds[valid_idx_inner] = valid_pred\n",
    "\n",
    "            fold_inner_scores.append(balanced_log_loss(y_valid, valid_pred))\n",
    "            print(f\"Outer fold {fold+1}, Inner fold {fold_inner+1} OOF CV: {fold_inner_scores[-1]:.4f}\")\n",
    "\n",
    "            models.append(model)\n",
    "            \n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "            \n",
    "        print(f\"mean/std: {np.mean(fold_inner_scores):.4f}/{np.std(fold_inner_scores):.4f}\")\n",
    "        score = balanced_log_loss(df_train_inner[\"Class\"], oof_inner_preds)\n",
    "        print(f\"Inner OOF CV score is {score:.4f}\")\n",
    "        fold_scores_.append(score)\n",
    "        \n",
    "        valid_pred = np.zeros(len(x_valid_outer))\n",
    "        for model in models:\n",
    "            if config[\"method\"] == \"catboost\":\n",
    "                valid_pred += model.predict_proba(x_valid_outer)[:, 1]\n",
    "            if config[\"method\"] == \"lightgbm\":\n",
    "                valid_pred += model.predict(x_valid_outer)\n",
    "            if config[\"method\"] == \"xgboost\":\n",
    "                valid_pred += model.predict(xgb.DMatrix(x_valid_outer), iteration_range=(0, model.best_ntree_limit))\n",
    "        valid_pred = valid_pred / config[\"folds\"][\"n_splits\"]\n",
    "        \n",
    "        oof_preds[valid_idx] = valid_pred\n",
    "\n",
    "        fold_scores.append(balanced_log_loss(y_valid_outer, valid_pred))\n",
    "        print(f\"Outer Fold {fold+1} OOF CV: {fold_scores[-1]:.4f}\")\n",
    "    \n",
    "    print(\"\")\n",
    "    for i in range(config[\"folds\"][\"n_splits\"]):\n",
    "        print(f\"{fold_scores[i]:.4f} {fold_scores_[i]:.4f}\")\n",
    "    print(f\"mean/std: {np.mean(fold_scores):.4f}/{np.std(fold_scores):.4f}\")\n",
    "    print(f\"mean/std_: {np.mean(fold_scores_):.4f}/{np.std(fold_scores_):.4f}\")\n",
    "    score = balanced_log_loss(df_train[\"Class\"], oof_preds)\n",
    "    print(f\"Outer OOF CV score is {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d773b65-f35c-4db5-88bd-181205dc9a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training xgboost model\n",
      "\n",
      "[0]\ttrain-logloss:0.67558\teval-logloss:0.67499\n",
      "[100]\ttrain-logloss:0.19361\teval-logloss:0.32319\n",
      "[200]\ttrain-logloss:0.07341\teval-logloss:0.25595\n",
      "[300]\ttrain-logloss:0.03077\teval-logloss:0.23198\n",
      "[400]\ttrain-logloss:0.01528\teval-logloss:0.23984\n",
      "[500]\ttrain-logloss:0.00985\teval-logloss:0.23830\n",
      "[600]\ttrain-logloss:0.00748\teval-logloss:0.24214\n",
      "[700]\ttrain-logloss:0.00622\teval-logloss:0.24813\n",
      "[800]\ttrain-logloss:0.00543\teval-logloss:0.25289\n",
      "[900]\ttrain-logloss:0.00496\teval-logloss:0.25799\n",
      "[1000]\ttrain-logloss:0.00468\teval-logloss:0.26219\n",
      "[1100]\ttrain-logloss:0.00445\teval-logloss:0.26354\n",
      "[1200]\ttrain-logloss:0.00422\teval-logloss:0.26421\n",
      "[1300]\ttrain-logloss:0.00408\teval-logloss:0.26348\n",
      "[1311]\ttrain-logloss:0.00406\teval-logloss:0.26306\n",
      "Outer fold 1, Inner fold 1 OOF CV: 0.2300\n",
      "[0]\ttrain-logloss:0.67499\teval-logloss:0.67941\n",
      "[100]\ttrain-logloss:0.18893\teval-logloss:0.29181\n",
      "[200]\ttrain-logloss:0.07041\teval-logloss:0.24120\n",
      "[300]\ttrain-logloss:0.02922\teval-logloss:0.25767\n",
      "[400]\ttrain-logloss:0.01436\teval-logloss:0.27590\n",
      "[500]\ttrain-logloss:0.00934\teval-logloss:0.29588\n",
      "[600]\ttrain-logloss:0.00719\teval-logloss:0.29944\n",
      "[700]\ttrain-logloss:0.00602\teval-logloss:0.31163\n",
      "[800]\ttrain-logloss:0.00532\teval-logloss:0.31610\n",
      "[900]\ttrain-logloss:0.00490\teval-logloss:0.32273\n",
      "[1000]\ttrain-logloss:0.00466\teval-logloss:0.32302\n",
      "[1100]\ttrain-logloss:0.00445\teval-logloss:0.32753\n",
      "[1200]\ttrain-logloss:0.00426\teval-logloss:0.33198\n",
      "[1237]\ttrain-logloss:0.00420\teval-logloss:0.33480\n",
      "Outer fold 1, Inner fold 2 OOF CV: 0.2398\n",
      "[0]\ttrain-logloss:0.67354\teval-logloss:0.67900\n",
      "[100]\ttrain-logloss:0.17537\teval-logloss:0.32849\n",
      "[200]\ttrain-logloss:0.06470\teval-logloss:0.33082\n",
      "[300]\ttrain-logloss:0.02673\teval-logloss:0.35127\n",
      "[400]\ttrain-logloss:0.01371\teval-logloss:0.37812\n",
      "[500]\ttrain-logloss:0.00896\teval-logloss:0.40359\n",
      "[600]\ttrain-logloss:0.00691\teval-logloss:0.41445\n",
      "[700]\ttrain-logloss:0.00585\teval-logloss:0.42086\n",
      "[800]\ttrain-logloss:0.00522\teval-logloss:0.42534\n",
      "[900]\ttrain-logloss:0.00483\teval-logloss:0.43092\n",
      "[1000]\ttrain-logloss:0.00457\teval-logloss:0.43328\n",
      "[1100]\ttrain-logloss:0.00439\teval-logloss:0.43669\n",
      "[1112]\ttrain-logloss:0.00436\teval-logloss:0.43873\n",
      "Outer fold 1, Inner fold 3 OOF CV: 0.3229\n",
      "[0]\ttrain-logloss:0.67898\teval-logloss:0.68484\n",
      "[100]\ttrain-logloss:0.20742\teval-logloss:0.32716\n",
      "[200]\ttrain-logloss:0.07734\teval-logloss:0.22674\n",
      "[300]\ttrain-logloss:0.03285\teval-logloss:0.19569\n",
      "[400]\ttrain-logloss:0.01619\teval-logloss:0.19391\n",
      "[500]\ttrain-logloss:0.01017\teval-logloss:0.18501\n",
      "[600]\ttrain-logloss:0.00772\teval-logloss:0.18424\n",
      "[700]\ttrain-logloss:0.00639\teval-logloss:0.18610\n",
      "[800]\ttrain-logloss:0.00558\teval-logloss:0.18649\n",
      "[900]\ttrain-logloss:0.00510\teval-logloss:0.18646\n",
      "[1000]\ttrain-logloss:0.00480\teval-logloss:0.18308\n",
      "[1100]\ttrain-logloss:0.00457\teval-logloss:0.17997\n",
      "[1200]\ttrain-logloss:0.00439\teval-logloss:0.17978\n",
      "[1300]\ttrain-logloss:0.00424\teval-logloss:0.17679\n",
      "[1400]\ttrain-logloss:0.00407\teval-logloss:0.17680\n",
      "[1500]\ttrain-logloss:0.00394\teval-logloss:0.17788\n",
      "[1600]\ttrain-logloss:0.00383\teval-logloss:0.17939\n",
      "[1700]\ttrain-logloss:0.00375\teval-logloss:0.18156\n",
      "[1800]\ttrain-logloss:0.00366\teval-logloss:0.18193\n",
      "[1900]\ttrain-logloss:0.00359\teval-logloss:0.18227\n",
      "[2000]\ttrain-logloss:0.00354\teval-logloss:0.18346\n",
      "[2100]\ttrain-logloss:0.00349\teval-logloss:0.18465\n",
      "[2200]\ttrain-logloss:0.00344\teval-logloss:0.18477\n",
      "[2300]\ttrain-logloss:0.00340\teval-logloss:0.18536\n",
      "[2400]\ttrain-logloss:0.00337\teval-logloss:0.18645\n",
      "[2411]\ttrain-logloss:0.00337\teval-logloss:0.18665\n",
      "Outer fold 1, Inner fold 4 OOF CV: 0.1763\n",
      "[0]\ttrain-logloss:0.67871\teval-logloss:0.68022\n",
      "[100]\ttrain-logloss:0.20976\teval-logloss:0.32574\n",
      "[200]\ttrain-logloss:0.07869\teval-logloss:0.23565\n",
      "[300]\ttrain-logloss:0.03255\teval-logloss:0.20838\n",
      "[400]\ttrain-logloss:0.01612\teval-logloss:0.20136\n",
      "[500]\ttrain-logloss:0.01010\teval-logloss:0.20369\n",
      "[600]\ttrain-logloss:0.00770\teval-logloss:0.20416\n",
      "[700]\ttrain-logloss:0.00645\teval-logloss:0.20297\n",
      "[800]\ttrain-logloss:0.00566\teval-logloss:0.20700\n",
      "[900]\ttrain-logloss:0.00513\teval-logloss:0.20755\n",
      "[1000]\ttrain-logloss:0.00484\teval-logloss:0.20933\n",
      "[1100]\ttrain-logloss:0.00461\teval-logloss:0.21309\n",
      "[1200]\ttrain-logloss:0.00440\teval-logloss:0.21462\n",
      "[1300]\ttrain-logloss:0.00425\teval-logloss:0.22116\n",
      "[1400]\ttrain-logloss:0.00409\teval-logloss:0.22342\n",
      "[1420]\ttrain-logloss:0.00405\teval-logloss:0.22429\n",
      "Outer fold 1, Inner fold 5 OOF CV: 0.1986\n",
      "mean/std: 0.2335/0.0501\n",
      "Inner OOF CV score is 0.2353\n",
      "Outer Fold 1 OOF CV: 0.1605\n",
      "\n",
      "[0]\ttrain-logloss:0.67592\teval-logloss:0.68014\n",
      "[100]\ttrain-logloss:0.17816\teval-logloss:0.29167\n",
      "[200]\ttrain-logloss:0.06131\teval-logloss:0.17372\n",
      "[300]\ttrain-logloss:0.02448\teval-logloss:0.12543\n",
      "[400]\ttrain-logloss:0.01248\teval-logloss:0.09811\n",
      "[500]\ttrain-logloss:0.00828\teval-logloss:0.08927\n",
      "[600]\ttrain-logloss:0.00655\teval-logloss:0.08213\n",
      "[700]\ttrain-logloss:0.00556\teval-logloss:0.07886\n",
      "[800]\ttrain-logloss:0.00502\teval-logloss:0.07770\n",
      "[900]\ttrain-logloss:0.00469\teval-logloss:0.07729\n",
      "[1000]\ttrain-logloss:0.00443\teval-logloss:0.07816\n",
      "[1100]\ttrain-logloss:0.00420\teval-logloss:0.07873\n",
      "[1200]\ttrain-logloss:0.00399\teval-logloss:0.07914\n",
      "[1300]\ttrain-logloss:0.00382\teval-logloss:0.07948\n",
      "[1400]\ttrain-logloss:0.00368\teval-logloss:0.08043\n",
      "[1500]\ttrain-logloss:0.00356\teval-logloss:0.08075\n",
      "[1600]\ttrain-logloss:0.00347\teval-logloss:0.08087\n",
      "[1700]\ttrain-logloss:0.00340\teval-logloss:0.08148\n",
      "[1800]\ttrain-logloss:0.00334\teval-logloss:0.08229\n",
      "[1851]\ttrain-logloss:0.00331\teval-logloss:0.08273\n",
      "Outer fold 2, Inner fold 1 OOF CV: 0.0772\n",
      "[0]\ttrain-logloss:0.67378\teval-logloss:0.68060\n",
      "[100]\ttrain-logloss:0.16456\teval-logloss:0.32123\n",
      "[200]\ttrain-logloss:0.05232\teval-logloss:0.29744\n",
      "[300]\ttrain-logloss:0.01962\teval-logloss:0.32440\n",
      "[400]\ttrain-logloss:0.01032\teval-logloss:0.34845\n",
      "[500]\ttrain-logloss:0.00725\teval-logloss:0.37589\n",
      "[600]\ttrain-logloss:0.00586\teval-logloss:0.39261\n",
      "[700]\ttrain-logloss:0.00508\teval-logloss:0.40682\n",
      "[800]\ttrain-logloss:0.00469\teval-logloss:0.40941\n",
      "[900]\ttrain-logloss:0.00438\teval-logloss:0.41891\n",
      "[1000]\ttrain-logloss:0.00415\teval-logloss:0.42375\n",
      "[1100]\ttrain-logloss:0.00393\teval-logloss:0.43206\n",
      "[1173]\ttrain-logloss:0.00382\teval-logloss:0.43700\n",
      "Outer fold 2, Inner fold 2 OOF CV: 0.2909\n",
      "[0]\ttrain-logloss:0.67433\teval-logloss:0.67498\n",
      "[100]\ttrain-logloss:0.16815\teval-logloss:0.21868\n",
      "[200]\ttrain-logloss:0.05801\teval-logloss:0.14008\n",
      "[300]\ttrain-logloss:0.02285\teval-logloss:0.11200\n",
      "[400]\ttrain-logloss:0.01152\teval-logloss:0.10338\n",
      "[500]\ttrain-logloss:0.00784\teval-logloss:0.10128\n",
      "[600]\ttrain-logloss:0.00617\teval-logloss:0.10047\n",
      "[700]\ttrain-logloss:0.00527\teval-logloss:0.10086\n",
      "[800]\ttrain-logloss:0.00481\teval-logloss:0.10167\n",
      "[900]\ttrain-logloss:0.00451\teval-logloss:0.10373\n",
      "[1000]\ttrain-logloss:0.00423\teval-logloss:0.10615\n",
      "[1100]\ttrain-logloss:0.00405\teval-logloss:0.10845\n",
      "[1200]\ttrain-logloss:0.00385\teval-logloss:0.11058\n",
      "[1300]\ttrain-logloss:0.00370\teval-logloss:0.11189\n",
      "[1400]\ttrain-logloss:0.00357\teval-logloss:0.11514\n",
      "[1500]\ttrain-logloss:0.00347\teval-logloss:0.11705\n",
      "[1569]\ttrain-logloss:0.00340\teval-logloss:0.11736\n",
      "Outer fold 2, Inner fold 3 OOF CV: 0.0999\n",
      "[0]\ttrain-logloss:0.67235\teval-logloss:0.67751\n",
      "[100]\ttrain-logloss:0.15314\teval-logloss:0.32165\n",
      "[200]\ttrain-logloss:0.05109\teval-logloss:0.28616\n",
      "[300]\ttrain-logloss:0.01947\teval-logloss:0.31671\n",
      "[400]\ttrain-logloss:0.01015\teval-logloss:0.34730\n",
      "[500]\ttrain-logloss:0.00717\teval-logloss:0.37364\n",
      "[600]\ttrain-logloss:0.00580\teval-logloss:0.39080\n",
      "[700]\ttrain-logloss:0.00508\teval-logloss:0.40551\n",
      "[800]\ttrain-logloss:0.00468\teval-logloss:0.41457\n",
      "[900]\ttrain-logloss:0.00439\teval-logloss:0.42324\n",
      "[1000]\ttrain-logloss:0.00410\teval-logloss:0.43034\n",
      "[1100]\ttrain-logloss:0.00390\teval-logloss:0.43687\n",
      "[1200]\ttrain-logloss:0.00371\teval-logloss:0.44508\n",
      "[1202]\ttrain-logloss:0.00370\teval-logloss:0.44522\n",
      "Outer fold 2, Inner fold 4 OOF CV: 0.2844\n",
      "[0]\ttrain-logloss:0.67509\teval-logloss:0.67277\n",
      "[100]\ttrain-logloss:0.18134\teval-logloss:0.24970\n",
      "[200]\ttrain-logloss:0.06516\teval-logloss:0.21807\n",
      "[300]\ttrain-logloss:0.02601\teval-logloss:0.24775\n",
      "[400]\ttrain-logloss:0.01300\teval-logloss:0.27405\n",
      "[500]\ttrain-logloss:0.00870\teval-logloss:0.29659\n",
      "[600]\ttrain-logloss:0.00683\teval-logloss:0.30499\n",
      "[700]\ttrain-logloss:0.00573\teval-logloss:0.32291\n",
      "[800]\ttrain-logloss:0.00513\teval-logloss:0.32722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain-logloss:0.00477\teval-logloss:0.33082\n",
      "[1000]\ttrain-logloss:0.00448\teval-logloss:0.33751\n",
      "[1100]\ttrain-logloss:0.00426\teval-logloss:0.33918\n",
      "[1185]\ttrain-logloss:0.00408\teval-logloss:0.34775\n",
      "Outer fold 2, Inner fold 5 OOF CV: 0.2120\n",
      "mean/std: 0.1929/0.0899\n",
      "Inner OOF CV score is 0.1923\n",
      "Outer Fold 2 OOF CV: 0.3529\n",
      "\n",
      "[0]\ttrain-logloss:0.67747\teval-logloss:0.67609\n",
      "[100]\ttrain-logloss:0.20279\teval-logloss:0.24226\n",
      "[200]\ttrain-logloss:0.07501\teval-logloss:0.17505\n",
      "[300]\ttrain-logloss:0.03028\teval-logloss:0.19359\n",
      "[400]\ttrain-logloss:0.01509\teval-logloss:0.22217\n",
      "[500]\ttrain-logloss:0.00951\teval-logloss:0.23232\n",
      "[600]\ttrain-logloss:0.00733\teval-logloss:0.25077\n",
      "[700]\ttrain-logloss:0.00613\teval-logloss:0.26444\n",
      "[800]\ttrain-logloss:0.00537\teval-logloss:0.26754\n",
      "[900]\ttrain-logloss:0.00485\teval-logloss:0.27135\n",
      "[1000]\ttrain-logloss:0.00462\teval-logloss:0.27132\n",
      "[1100]\ttrain-logloss:0.00440\teval-logloss:0.27135\n",
      "[1200]\ttrain-logloss:0.00422\teval-logloss:0.27107\n",
      "[1204]\ttrain-logloss:0.00421\teval-logloss:0.27074\n",
      "Outer fold 3, Inner fold 1 OOF CV: 0.1732\n",
      "[0]\ttrain-logloss:0.67626\teval-logloss:0.68231\n",
      "[100]\ttrain-logloss:0.18137\teval-logloss:0.38927\n",
      "[200]\ttrain-logloss:0.06799\teval-logloss:0.33644\n",
      "[300]\ttrain-logloss:0.02689\teval-logloss:0.32500\n",
      "[400]\ttrain-logloss:0.01333\teval-logloss:0.33124\n",
      "[500]\ttrain-logloss:0.00879\teval-logloss:0.34463\n",
      "[600]\ttrain-logloss:0.00676\teval-logloss:0.35610\n",
      "[700]\ttrain-logloss:0.00565\teval-logloss:0.36715\n",
      "[800]\ttrain-logloss:0.00509\teval-logloss:0.37417\n",
      "[900]\ttrain-logloss:0.00469\teval-logloss:0.38053\n",
      "[1000]\ttrain-logloss:0.00444\teval-logloss:0.38915\n",
      "[1100]\ttrain-logloss:0.00421\teval-logloss:0.39626\n",
      "[1200]\ttrain-logloss:0.00399\teval-logloss:0.40172\n",
      "[1282]\ttrain-logloss:0.00385\teval-logloss:0.40595\n",
      "Outer fold 3, Inner fold 2 OOF CV: 0.3221\n",
      "[0]\ttrain-logloss:0.67454\teval-logloss:0.67785\n",
      "[100]\ttrain-logloss:0.17259\teval-logloss:0.40070\n",
      "[200]\ttrain-logloss:0.06336\teval-logloss:0.36106\n",
      "[300]\ttrain-logloss:0.02559\teval-logloss:0.34838\n",
      "[400]\ttrain-logloss:0.01306\teval-logloss:0.34976\n",
      "[500]\ttrain-logloss:0.00872\teval-logloss:0.35894\n",
      "[600]\ttrain-logloss:0.00681\teval-logloss:0.36572\n",
      "[700]\ttrain-logloss:0.00581\teval-logloss:0.37324\n",
      "[800]\ttrain-logloss:0.00521\teval-logloss:0.36431\n",
      "[900]\ttrain-logloss:0.00486\teval-logloss:0.36708\n",
      "[1000]\ttrain-logloss:0.00461\teval-logloss:0.37111\n",
      "[1100]\ttrain-logloss:0.00438\teval-logloss:0.37914\n",
      "[1200]\ttrain-logloss:0.00418\teval-logloss:0.38414\n",
      "[1300]\ttrain-logloss:0.00402\teval-logloss:0.38851\n",
      "[1383]\ttrain-logloss:0.00391\teval-logloss:0.38992\n",
      "Outer fold 3, Inner fold 3 OOF CV: 0.3440\n",
      "[0]\ttrain-logloss:0.67879\teval-logloss:0.68284\n",
      "[100]\ttrain-logloss:0.19209\teval-logloss:0.34081\n",
      "[200]\ttrain-logloss:0.06602\teval-logloss:0.29019\n",
      "[300]\ttrain-logloss:0.02617\teval-logloss:0.31582\n",
      "[400]\ttrain-logloss:0.01262\teval-logloss:0.33792\n",
      "[500]\ttrain-logloss:0.00831\teval-logloss:0.35481\n",
      "[600]\ttrain-logloss:0.00650\teval-logloss:0.36165\n",
      "[700]\ttrain-logloss:0.00555\teval-logloss:0.36848\n",
      "[800]\ttrain-logloss:0.00498\teval-logloss:0.37416\n",
      "[900]\ttrain-logloss:0.00464\teval-logloss:0.37537\n",
      "[1000]\ttrain-logloss:0.00435\teval-logloss:0.38124\n",
      "[1100]\ttrain-logloss:0.00416\teval-logloss:0.38564\n",
      "[1200]\ttrain-logloss:0.00397\teval-logloss:0.38930\n",
      "[1204]\ttrain-logloss:0.00398\teval-logloss:0.38887\n",
      "Outer fold 3, Inner fold 4 OOF CV: 0.2864\n",
      "[0]\ttrain-logloss:0.67715\teval-logloss:0.68079\n",
      "[100]\ttrain-logloss:0.21243\teval-logloss:0.25683\n",
      "[200]\ttrain-logloss:0.07853\teval-logloss:0.17008\n",
      "[300]\ttrain-logloss:0.03279\teval-logloss:0.15300\n",
      "[400]\ttrain-logloss:0.01616\teval-logloss:0.14982\n",
      "[500]\ttrain-logloss:0.01005\teval-logloss:0.14523\n",
      "[600]\ttrain-logloss:0.00756\teval-logloss:0.14567\n",
      "[700]\ttrain-logloss:0.00626\teval-logloss:0.14668\n",
      "[800]\ttrain-logloss:0.00553\teval-logloss:0.14402\n",
      "[900]\ttrain-logloss:0.00503\teval-logloss:0.14441\n",
      "[1000]\ttrain-logloss:0.00467\teval-logloss:0.14277\n",
      "[1100]\ttrain-logloss:0.00445\teval-logloss:0.14524\n",
      "[1200]\ttrain-logloss:0.00425\teval-logloss:0.14662\n",
      "[1300]\ttrain-logloss:0.00410\teval-logloss:0.14662\n",
      "[1400]\ttrain-logloss:0.00397\teval-logloss:0.14801\n",
      "[1500]\ttrain-logloss:0.00383\teval-logloss:0.14895\n",
      "[1600]\ttrain-logloss:0.00372\teval-logloss:0.14960\n",
      "[1700]\ttrain-logloss:0.00361\teval-logloss:0.15171\n",
      "[1800]\ttrain-logloss:0.00352\teval-logloss:0.15140\n",
      "[1845]\ttrain-logloss:0.00350\teval-logloss:0.15187\n",
      "Outer fold 3, Inner fold 5 OOF CV: 0.1422\n",
      "mean/std: 0.2536/0.0810\n",
      "Inner OOF CV score is 0.2478\n",
      "Outer Fold 3 OOF CV: 0.1727\n",
      "\n",
      "[0]\ttrain-logloss:0.67482\teval-logloss:0.67875\n",
      "[100]\ttrain-logloss:0.17741\teval-logloss:0.34945\n",
      "[200]\ttrain-logloss:0.06017\teval-logloss:0.34563\n",
      "[300]\ttrain-logloss:0.02407\teval-logloss:0.39691\n",
      "[400]\ttrain-logloss:0.01212\teval-logloss:0.44807\n",
      "[500]\ttrain-logloss:0.00825\teval-logloss:0.48661\n",
      "[600]\ttrain-logloss:0.00647\teval-logloss:0.51116\n",
      "[700]\ttrain-logloss:0.00547\teval-logloss:0.52286\n",
      "[800]\ttrain-logloss:0.00493\teval-logloss:0.53536\n",
      "[900]\ttrain-logloss:0.00461\teval-logloss:0.53928\n",
      "[1000]\ttrain-logloss:0.00436\teval-logloss:0.54500\n",
      "[1100]\ttrain-logloss:0.00418\teval-logloss:0.54829\n",
      "[1141]\ttrain-logloss:0.00411\teval-logloss:0.55108\n",
      "Outer fold 4, Inner fold 1 OOF CV: 0.3332\n",
      "[0]\ttrain-logloss:0.67298\teval-logloss:0.67945\n",
      "[100]\ttrain-logloss:0.18666\teval-logloss:0.29662\n",
      "[200]\ttrain-logloss:0.06535\teval-logloss:0.22660\n",
      "[300]\ttrain-logloss:0.02561\teval-logloss:0.22425\n",
      "[400]\ttrain-logloss:0.01251\teval-logloss:0.23141\n",
      "[500]\ttrain-logloss:0.00824\teval-logloss:0.23938\n",
      "[600]\ttrain-logloss:0.00650\teval-logloss:0.24773\n",
      "[700]\ttrain-logloss:0.00552\teval-logloss:0.25770\n",
      "[800]\ttrain-logloss:0.00492\teval-logloss:0.26414\n",
      "[900]\ttrain-logloss:0.00456\teval-logloss:0.26103\n",
      "[1000]\ttrain-logloss:0.00431\teval-logloss:0.26109\n",
      "[1100]\ttrain-logloss:0.00413\teval-logloss:0.26466\n",
      "[1200]\ttrain-logloss:0.00397\teval-logloss:0.26946\n",
      "[1228]\ttrain-logloss:0.00392\teval-logloss:0.26934\n",
      "Outer fold 4, Inner fold 2 OOF CV: 0.2158\n",
      "[0]\ttrain-logloss:0.67716\teval-logloss:0.67900\n",
      "[100]\ttrain-logloss:0.18797\teval-logloss:0.32850\n",
      "[200]\ttrain-logloss:0.06890\teval-logloss:0.30392\n",
      "[300]\ttrain-logloss:0.02825\teval-logloss:0.34314\n",
      "[400]\ttrain-logloss:0.01393\teval-logloss:0.37032\n",
      "[500]\ttrain-logloss:0.00907\teval-logloss:0.39600\n",
      "[600]\ttrain-logloss:0.00701\teval-logloss:0.42336\n",
      "[700]\ttrain-logloss:0.00587\teval-logloss:0.43649\n",
      "[800]\ttrain-logloss:0.00517\teval-logloss:0.45148\n",
      "[900]\ttrain-logloss:0.00478\teval-logloss:0.45827\n",
      "[1000]\ttrain-logloss:0.00452\teval-logloss:0.46378\n",
      "[1100]\ttrain-logloss:0.00429\teval-logloss:0.47195\n",
      "[1178]\ttrain-logloss:0.00412\teval-logloss:0.47801\n",
      "Outer fold 4, Inner fold 3 OOF CV: 0.2960\n",
      "[0]\ttrain-logloss:0.67248\teval-logloss:0.67886\n",
      "[100]\ttrain-logloss:0.15900\teval-logloss:0.34124\n",
      "[200]\ttrain-logloss:0.05563\teval-logloss:0.31353\n",
      "[300]\ttrain-logloss:0.02206\teval-logloss:0.33819\n",
      "[400]\ttrain-logloss:0.01121\teval-logloss:0.36084\n",
      "[500]\ttrain-logloss:0.00777\teval-logloss:0.37986\n",
      "[600]\ttrain-logloss:0.00619\teval-logloss:0.39488\n",
      "[700]\ttrain-logloss:0.00530\teval-logloss:0.40321\n",
      "[800]\ttrain-logloss:0.00483\teval-logloss:0.41152\n",
      "[900]\ttrain-logloss:0.00455\teval-logloss:0.41656\n",
      "[1000]\ttrain-logloss:0.00428\teval-logloss:0.42149\n",
      "[1100]\ttrain-logloss:0.00407\teval-logloss:0.42514\n",
      "[1194]\ttrain-logloss:0.00392\teval-logloss:0.42994\n",
      "Outer fold 4, Inner fold 4 OOF CV: 0.3119\n",
      "[0]\ttrain-logloss:0.67482\teval-logloss:0.68193\n",
      "[100]\ttrain-logloss:0.17626\teval-logloss:0.33728\n",
      "[200]\ttrain-logloss:0.06320\teval-logloss:0.25227\n",
      "[300]\ttrain-logloss:0.02484\teval-logloss:0.22590\n",
      "[400]\ttrain-logloss:0.01250\teval-logloss:0.22928\n",
      "[500]\ttrain-logloss:0.00835\teval-logloss:0.23320\n",
      "[600]\ttrain-logloss:0.00655\teval-logloss:0.23140\n",
      "[700]\ttrain-logloss:0.00554\teval-logloss:0.22774\n",
      "[800]\ttrain-logloss:0.00499\teval-logloss:0.22610\n",
      "[900]\ttrain-logloss:0.00468\teval-logloss:0.22613\n",
      "[1000]\ttrain-logloss:0.00444\teval-logloss:0.22436\n",
      "[1100]\ttrain-logloss:0.00424\teval-logloss:0.22285\n",
      "[1200]\ttrain-logloss:0.00405\teval-logloss:0.22063\n",
      "[1300]\ttrain-logloss:0.00389\teval-logloss:0.22026\n",
      "[1400]\ttrain-logloss:0.00379\teval-logloss:0.22011\n",
      "[1500]\ttrain-logloss:0.00367\teval-logloss:0.21787\n",
      "[1600]\ttrain-logloss:0.00355\teval-logloss:0.21692\n",
      "[1700]\ttrain-logloss:0.00346\teval-logloss:0.21643\n",
      "[1800]\ttrain-logloss:0.00340\teval-logloss:0.21380\n",
      "[1900]\ttrain-logloss:0.00333\teval-logloss:0.21286\n",
      "[2000]\ttrain-logloss:0.00329\teval-logloss:0.21270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\ttrain-logloss:0.00323\teval-logloss:0.21149\n",
      "[2200]\ttrain-logloss:0.00320\teval-logloss:0.21042\n",
      "[2300]\ttrain-logloss:0.00318\teval-logloss:0.21025\n",
      "[2400]\ttrain-logloss:0.00316\teval-logloss:0.20986\n",
      "[2500]\ttrain-logloss:0.00315\teval-logloss:0.20902\n",
      "[2600]\ttrain-logloss:0.00313\teval-logloss:0.20916\n",
      "[2700]\ttrain-logloss:0.00313\teval-logloss:0.20846\n",
      "[2800]\ttrain-logloss:0.00312\teval-logloss:0.20847\n",
      "[2900]\ttrain-logloss:0.00312\teval-logloss:0.20841\n",
      "[3000]\ttrain-logloss:0.00310\teval-logloss:0.20881\n",
      "[3100]\ttrain-logloss:0.00310\teval-logloss:0.20844\n",
      "[3200]\ttrain-logloss:0.00310\teval-logloss:0.20833\n",
      "[3300]\ttrain-logloss:0.00310\teval-logloss:0.20782\n",
      "[3400]\ttrain-logloss:0.00309\teval-logloss:0.20743\n",
      "[3500]\ttrain-logloss:0.00309\teval-logloss:0.20752\n",
      "[3600]\ttrain-logloss:0.00307\teval-logloss:0.20742\n",
      "[3700]\ttrain-logloss:0.00308\teval-logloss:0.20738\n",
      "[3800]\ttrain-logloss:0.00308\teval-logloss:0.20718\n",
      "[3900]\ttrain-logloss:0.00307\teval-logloss:0.20711\n",
      "[4000]\ttrain-logloss:0.00307\teval-logloss:0.20686\n",
      "[4100]\ttrain-logloss:0.00307\teval-logloss:0.20698\n",
      "[4200]\ttrain-logloss:0.00306\teval-logloss:0.20714\n",
      "[4300]\ttrain-logloss:0.00307\teval-logloss:0.20683\n",
      "[4400]\ttrain-logloss:0.00307\teval-logloss:0.20681\n",
      "[4500]\ttrain-logloss:0.00306\teval-logloss:0.20696\n",
      "[4600]\ttrain-logloss:0.00306\teval-logloss:0.20685\n",
      "[4700]\ttrain-logloss:0.00305\teval-logloss:0.20696\n",
      "[4800]\ttrain-logloss:0.00305\teval-logloss:0.20671\n",
      "[4900]\ttrain-logloss:0.00306\teval-logloss:0.20651\n",
      "[5000]\ttrain-logloss:0.00305\teval-logloss:0.20658\n",
      "[5100]\ttrain-logloss:0.00305\teval-logloss:0.20666\n",
      "[5200]\ttrain-logloss:0.00306\teval-logloss:0.20662\n",
      "[5300]\ttrain-logloss:0.00305\teval-logloss:0.20622\n",
      "[5400]\ttrain-logloss:0.00305\teval-logloss:0.20616\n",
      "[5500]\ttrain-logloss:0.00304\teval-logloss:0.20645\n",
      "[5600]\ttrain-logloss:0.00305\teval-logloss:0.20631\n",
      "[5700]\ttrain-logloss:0.00305\teval-logloss:0.20621\n",
      "[5800]\ttrain-logloss:0.00305\teval-logloss:0.20621\n",
      "[5900]\ttrain-logloss:0.00304\teval-logloss:0.20623\n",
      "[6000]\ttrain-logloss:0.00305\teval-logloss:0.20620\n",
      "[6100]\ttrain-logloss:0.00305\teval-logloss:0.20602\n",
      "[6200]\ttrain-logloss:0.00304\teval-logloss:0.20606\n",
      "[6300]\ttrain-logloss:0.00305\teval-logloss:0.20584\n",
      "[6400]\ttrain-logloss:0.00304\teval-logloss:0.20565\n",
      "[6500]\ttrain-logloss:0.00303\teval-logloss:0.20555\n",
      "[6600]\ttrain-logloss:0.00304\teval-logloss:0.20560\n",
      "[6700]\ttrain-logloss:0.00303\teval-logloss:0.20540\n",
      "[6800]\ttrain-logloss:0.00304\teval-logloss:0.20539\n",
      "[6900]\ttrain-logloss:0.00304\teval-logloss:0.20534\n",
      "[7000]\ttrain-logloss:0.00303\teval-logloss:0.20535\n",
      "[7100]\ttrain-logloss:0.00303\teval-logloss:0.20527\n",
      "[7200]\ttrain-logloss:0.00304\teval-logloss:0.20514\n",
      "[7300]\ttrain-logloss:0.00302\teval-logloss:0.20532\n",
      "[7400]\ttrain-logloss:0.00304\teval-logloss:0.20524\n",
      "[7500]\ttrain-logloss:0.00304\teval-logloss:0.20531\n",
      "[7600]\ttrain-logloss:0.00303\teval-logloss:0.20525\n",
      "[7700]\ttrain-logloss:0.00303\teval-logloss:0.20530\n",
      "[7800]\ttrain-logloss:0.00303\teval-logloss:0.20534\n",
      "[7900]\ttrain-logloss:0.00304\teval-logloss:0.20529\n",
      "[8000]\ttrain-logloss:0.00304\teval-logloss:0.20522\n",
      "[8100]\ttrain-logloss:0.00304\teval-logloss:0.20520\n",
      "[8200]\ttrain-logloss:0.00304\teval-logloss:0.20506\n",
      "[8300]\ttrain-logloss:0.00303\teval-logloss:0.20514\n",
      "[8400]\ttrain-logloss:0.00303\teval-logloss:0.20485\n",
      "[8500]\ttrain-logloss:0.00303\teval-logloss:0.20476\n",
      "[8600]\ttrain-logloss:0.00304\teval-logloss:0.20472\n",
      "[8700]\ttrain-logloss:0.00303\teval-logloss:0.20475\n",
      "[8800]\ttrain-logloss:0.00303\teval-logloss:0.20496\n",
      "[8900]\ttrain-logloss:0.00303\teval-logloss:0.20490\n",
      "[9000]\ttrain-logloss:0.00303\teval-logloss:0.20489\n",
      "[9100]\ttrain-logloss:0.00303\teval-logloss:0.20493\n",
      "[9200]\ttrain-logloss:0.00303\teval-logloss:0.20488\n",
      "[9300]\ttrain-logloss:0.00303\teval-logloss:0.20476\n",
      "[9400]\ttrain-logloss:0.00303\teval-logloss:0.20471\n",
      "[9500]\ttrain-logloss:0.00302\teval-logloss:0.20482\n",
      "[9600]\ttrain-logloss:0.00303\teval-logloss:0.20482\n",
      "[9700]\ttrain-logloss:0.00302\teval-logloss:0.20487\n",
      "[9800]\ttrain-logloss:0.00303\teval-logloss:0.20489\n",
      "[9900]\ttrain-logloss:0.00303\teval-logloss:0.20487\n",
      "[10000]\ttrain-logloss:0.00303\teval-logloss:0.20476\n",
      "[10100]\ttrain-logloss:0.00303\teval-logloss:0.20486\n",
      "[10200]\ttrain-logloss:0.00303\teval-logloss:0.20469\n",
      "[10300]\ttrain-logloss:0.00303\teval-logloss:0.20460\n",
      "[10400]\ttrain-logloss:0.00302\teval-logloss:0.20456\n",
      "[10500]\ttrain-logloss:0.00303\teval-logloss:0.20449\n",
      "[10600]\ttrain-logloss:0.00302\teval-logloss:0.20462\n",
      "[10700]\ttrain-logloss:0.00302\teval-logloss:0.20461\n",
      "[10800]\ttrain-logloss:0.00302\teval-logloss:0.20455\n",
      "[10900]\ttrain-logloss:0.00302\teval-logloss:0.20460\n",
      "[11000]\ttrain-logloss:0.00302\teval-logloss:0.20448\n",
      "[11100]\ttrain-logloss:0.00303\teval-logloss:0.20447\n",
      "[11200]\ttrain-logloss:0.00302\teval-logloss:0.20452\n",
      "[11300]\ttrain-logloss:0.00302\teval-logloss:0.20448\n",
      "[11400]\ttrain-logloss:0.00302\teval-logloss:0.20433\n",
      "[11500]\ttrain-logloss:0.00302\teval-logloss:0.20437\n",
      "[11600]\ttrain-logloss:0.00302\teval-logloss:0.20444\n",
      "[11700]\ttrain-logloss:0.00301\teval-logloss:0.20467\n",
      "[11800]\ttrain-logloss:0.00301\teval-logloss:0.20466\n",
      "[11900]\ttrain-logloss:0.00302\teval-logloss:0.20467\n",
      "[12000]\ttrain-logloss:0.00302\teval-logloss:0.20472\n",
      "[12100]\ttrain-logloss:0.00302\teval-logloss:0.20475\n",
      "[12200]\ttrain-logloss:0.00302\teval-logloss:0.20472\n",
      "[12300]\ttrain-logloss:0.00302\teval-logloss:0.20472\n",
      "[12400]\ttrain-logloss:0.00302\teval-logloss:0.20474\n",
      "[12498]\ttrain-logloss:0.00301\teval-logloss:0.20475\n",
      "Outer fold 4, Inner fold 5 OOF CV: 0.2043\n",
      "mean/std: 0.2722/0.0523\n",
      "Inner OOF CV score is 0.2652\n",
      "Outer Fold 4 OOF CV: 0.2273\n",
      "\n",
      "[0]\ttrain-logloss:0.67510\teval-logloss:0.68065\n",
      "[100]\ttrain-logloss:0.19857\teval-logloss:0.29579\n",
      "[200]\ttrain-logloss:0.07344\teval-logloss:0.20232\n",
      "[300]\ttrain-logloss:0.03000\teval-logloss:0.15950\n",
      "[400]\ttrain-logloss:0.01486\teval-logloss:0.13626\n",
      "[500]\ttrain-logloss:0.00945\teval-logloss:0.12933\n",
      "[600]\ttrain-logloss:0.00714\teval-logloss:0.12536\n",
      "[700]\ttrain-logloss:0.00596\teval-logloss:0.12245\n",
      "[800]\ttrain-logloss:0.00527\teval-logloss:0.12170\n",
      "[900]\ttrain-logloss:0.00482\teval-logloss:0.12058\n",
      "[1000]\ttrain-logloss:0.00455\teval-logloss:0.11959\n",
      "[1100]\ttrain-logloss:0.00431\teval-logloss:0.11977\n",
      "[1200]\ttrain-logloss:0.00411\teval-logloss:0.11922\n",
      "[1300]\ttrain-logloss:0.00395\teval-logloss:0.11713\n",
      "[1400]\ttrain-logloss:0.00384\teval-logloss:0.11822\n",
      "[1500]\ttrain-logloss:0.00372\teval-logloss:0.11831\n",
      "[1600]\ttrain-logloss:0.00363\teval-logloss:0.11806\n",
      "[1700]\ttrain-logloss:0.00354\teval-logloss:0.11909\n",
      "[1800]\ttrain-logloss:0.00347\teval-logloss:0.11973\n",
      "[1900]\ttrain-logloss:0.00340\teval-logloss:0.12016\n",
      "[2000]\ttrain-logloss:0.00336\teval-logloss:0.12028\n",
      "[2100]\ttrain-logloss:0.00333\teval-logloss:0.12076\n",
      "[2200]\ttrain-logloss:0.00330\teval-logloss:0.12104\n",
      "[2300]\ttrain-logloss:0.00328\teval-logloss:0.12112\n",
      "[2308]\ttrain-logloss:0.00328\teval-logloss:0.12102\n",
      "Outer fold 5, Inner fold 1 OOF CV: 0.1169\n",
      "[0]\ttrain-logloss:0.67712\teval-logloss:0.67725\n",
      "[100]\ttrain-logloss:0.18020\teval-logloss:0.38730\n",
      "[200]\ttrain-logloss:0.06201\teval-logloss:0.35212\n",
      "[300]\ttrain-logloss:0.02501\teval-logloss:0.36310\n",
      "[400]\ttrain-logloss:0.01279\teval-logloss:0.39284\n",
      "[500]\ttrain-logloss:0.00850\teval-logloss:0.42366\n",
      "[600]\ttrain-logloss:0.00662\teval-logloss:0.44274\n",
      "[700]\ttrain-logloss:0.00558\teval-logloss:0.45429\n",
      "[800]\ttrain-logloss:0.00501\teval-logloss:0.46360\n",
      "[900]\ttrain-logloss:0.00471\teval-logloss:0.46761\n",
      "[1000]\ttrain-logloss:0.00445\teval-logloss:0.48021\n",
      "[1100]\ttrain-logloss:0.00428\teval-logloss:0.48698\n",
      "[1200]\ttrain-logloss:0.00410\teval-logloss:0.49135\n",
      "[1211]\ttrain-logloss:0.00408\teval-logloss:0.49070\n",
      "Outer fold 5, Inner fold 2 OOF CV: 0.3494\n",
      "[0]\ttrain-logloss:0.67822\teval-logloss:0.68542\n",
      "[100]\ttrain-logloss:0.18544\teval-logloss:0.42632\n",
      "[200]\ttrain-logloss:0.06794\teval-logloss:0.40687\n",
      "[300]\ttrain-logloss:0.02761\teval-logloss:0.43396\n",
      "[400]\ttrain-logloss:0.01400\teval-logloss:0.46365\n",
      "[500]\ttrain-logloss:0.00908\teval-logloss:0.49324\n",
      "[600]\ttrain-logloss:0.00692\teval-logloss:0.52584\n",
      "[700]\ttrain-logloss:0.00583\teval-logloss:0.53283\n",
      "[800]\ttrain-logloss:0.00521\teval-logloss:0.54799\n",
      "[900]\ttrain-logloss:0.00484\teval-logloss:0.55376\n",
      "[1000]\ttrain-logloss:0.00454\teval-logloss:0.56255\n",
      "[1100]\ttrain-logloss:0.00431\teval-logloss:0.56346\n",
      "[1140]\ttrain-logloss:0.00423\teval-logloss:0.56463\n",
      "Outer fold 5, Inner fold 3 OOF CV: 0.3997\n",
      "[0]\ttrain-logloss:0.68104\teval-logloss:0.68050\n",
      "[100]\ttrain-logloss:0.20897\teval-logloss:0.26513\n",
      "[200]\ttrain-logloss:0.07676\teval-logloss:0.16379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain-logloss:0.03115\teval-logloss:0.13506\n",
      "[400]\ttrain-logloss:0.01525\teval-logloss:0.12459\n",
      "[500]\ttrain-logloss:0.00952\teval-logloss:0.12367\n",
      "[600]\ttrain-logloss:0.00723\teval-logloss:0.12362\n",
      "[700]\ttrain-logloss:0.00602\teval-logloss:0.12609\n",
      "[800]\ttrain-logloss:0.00523\teval-logloss:0.12554\n",
      "[900]\ttrain-logloss:0.00479\teval-logloss:0.12697\n",
      "[1000]\ttrain-logloss:0.00450\teval-logloss:0.13112\n",
      "[1100]\ttrain-logloss:0.00427\teval-logloss:0.13173\n",
      "[1200]\ttrain-logloss:0.00408\teval-logloss:0.13377\n",
      "[1300]\ttrain-logloss:0.00393\teval-logloss:0.13651\n",
      "[1400]\ttrain-logloss:0.00380\teval-logloss:0.13876\n",
      "[1500]\ttrain-logloss:0.00369\teval-logloss:0.14186\n",
      "[1558]\ttrain-logloss:0.00364\teval-logloss:0.14242\n",
      "Outer fold 5, Inner fold 4 OOF CV: 0.1215\n",
      "[0]\ttrain-logloss:0.68024\teval-logloss:0.68443\n",
      "[100]\ttrain-logloss:0.19331\teval-logloss:0.33052\n",
      "[200]\ttrain-logloss:0.06778\teval-logloss:0.28106\n",
      "[300]\ttrain-logloss:0.02669\teval-logloss:0.29443\n",
      "[400]\ttrain-logloss:0.01301\teval-logloss:0.31334\n",
      "[500]\ttrain-logloss:0.00848\teval-logloss:0.33348\n",
      "[600]\ttrain-logloss:0.00664\teval-logloss:0.34326\n",
      "[700]\ttrain-logloss:0.00560\teval-logloss:0.35701\n",
      "[800]\ttrain-logloss:0.00500\teval-logloss:0.36668\n",
      "[900]\ttrain-logloss:0.00464\teval-logloss:0.37289\n",
      "[1000]\ttrain-logloss:0.00439\teval-logloss:0.38105\n",
      "[1100]\ttrain-logloss:0.00417\teval-logloss:0.38751\n",
      "[1200]\ttrain-logloss:0.00397\teval-logloss:0.39313\n",
      "[1215]\ttrain-logloss:0.00395\teval-logloss:0.39439\n",
      "Outer fold 5, Inner fold 5 OOF CV: 0.2761\n",
      "mean/std: 0.2527/0.1159\n",
      "Inner OOF CV score is 0.2385\n",
      "Outer Fold 5 OOF CV: 0.1846\n",
      "\n",
      "0.1605 0.2353\n",
      "0.3529 0.1923\n",
      "0.1727 0.2478\n",
      "0.2273 0.2652\n",
      "0.1846 0.2385\n",
      "mean/std: 0.2196/0.0704\n",
      "mean/std_: 0.2358/0.0241\n",
      "Outer OOF CV score is 0.2232\n"
     ]
    }
   ],
   "source": [
    "run_training(\"config.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
