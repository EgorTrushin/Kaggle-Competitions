{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc8301b-a887-4d58-afcd-f81b4f761a91",
   "metadata": {},
   "source": [
    "# ICR - Identifying Age-Related Conditions: Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a542e5-dc47-47fa-95d3-03084a520052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "import yaml\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d620a42-977c-4a07-abbc-b563a527021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(data_path):\n",
    "    \"\"\"Reads and returns all competition data.\"\"\"\n",
    "    train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "    test = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "    greeks = pd.read_csv(os.path.join(data_path, \"greeks.csv\"))\n",
    "    sub = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "    train = train.rename(columns={\"BD \": \"BD\", \"CD \": \"CD\", \"CW \": \"CW\", \"FD \": \"FD\"})\n",
    "    test = test.rename(columns={\"BD \": \"BD\", \"CD \": \"CD\", \"CW \": \"CW\", \"FD \": \"FD\"})\n",
    "    return train, test, greeks, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267860dd-ef7b-478c-930e-6d12d21707bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    \"\"\"Competition metric.\"\"\"\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    balanced_log_loss_score = (\n",
    "        -1.0 / nc[0] * (np.sum(np.where(y_true == 0, 1, 0) * np.log(1 - y_pred)))\n",
    "        - 1.0 / nc[1] * (np.sum(np.where(y_true != 0, 1, 0) * np.log(y_pred)))\n",
    "    ) / 2.0\n",
    "    return balanced_log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56eb5d50-ba5c-406c-8fbc-2e4a80c0685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_loss_weight(y_true):\n",
    "    \"\"\"Calculates weights for dataset.\"\"\"\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1 / (nc[0] / y_true.shape[0]), 1 / (nc[1] / y_true.shape[0])\n",
    "    return w0, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c403a2-858b-4ba9-be70-7b5c6a8b5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(x_train, y_train, x_valid, y_valid, categorical_features, cat_params):\n",
    "    \"\"\"catboost training.\"\"\"\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "\n",
    "    cat_train = Pool(\n",
    "        data=x_train,\n",
    "        label=y_train,\n",
    "        weight=y_train.map({0: train_w0, 1: train_w1}),\n",
    "        cat_features=categorical_features,\n",
    "    )\n",
    "    cat_valid = Pool(\n",
    "        data=x_valid,\n",
    "        label=y_valid,\n",
    "        weight=y_valid.map({0: valid_w0, 1: valid_w1}),\n",
    "        cat_features=categorical_features,\n",
    "    )\n",
    "\n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(cat_train, eval_set=[cat_valid], use_best_model=True)\n",
    "\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e19892-00e6-48a0-b104-ffa22640bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(\n",
    "    x_train, y_train, x_valid, y_valid, categorical_features, lgb_params, train_params\n",
    "):\n",
    "    \"\"\"LightGBM training.\"\"\"\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        weight=y_train.map({0: train_w0, 1: train_w1}),\n",
    "    )\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        x_valid,\n",
    "        y_valid,\n",
    "        weight=y_valid.map({0: valid_w0, 1: valid_w1}),\n",
    "    )\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=lgb_params,\n",
    "        train_set=lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        num_boost_round=train_params[\"num_boost_round\"],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(train_params[\"stopping_rounds\"]),\n",
    "            lgb.log_evaluation(train_params[\"period\"]),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    valid_pred = model.predict(x_valid)\n",
    "\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d61c8de-42af-48a0-a609-009f1ade7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(x_train, y_train, x_valid, y_valid, categorical_features, xgb_params, train):\n",
    "    \"\"\"XGBoost training.\"\"\"\n",
    "    train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    xgb_train = xgb.DMatrix(\n",
    "        data=x_train, label=y_train, weight=y_train.map({0: train_w0, 1: train_w1})\n",
    "    )\n",
    "    xgb_valid = xgb.DMatrix(\n",
    "        data=x_valid, label=y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1})\n",
    "    )\n",
    "    xgb_params[\"scale_pos_weight\"] = train_w1 / train_w0\n",
    "    model = xgb.train(\n",
    "        xgb_params, dtrain=xgb_train, evals=[(xgb_train, \"train\"), (xgb_valid, \"eval\")], **train\n",
    "    )\n",
    "\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid), iteration_range=(0, model.best_ntree_limit))\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e144d6-6784-4874-a80a-960821100aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(config_path):\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as file_obj:\n",
    "        config = yaml.safe_load(file_obj)\n",
    "\n",
    "    print(config_path)\n",
    "    pprint(config)\n",
    "\n",
    "    df_train, _, df_greeks, _ = get_dataframes(config[\"data_path\"])\n",
    "\n",
    "    cat_features = [\"EJ\"]\n",
    "    num_features = list(df_train.columns)[1:-1]\n",
    "    num_features.remove(\"EJ\")\n",
    "    print(\"Original number of numerical features:\", len(num_features))\n",
    "    print(\"Original number of categorical features:\", len(cat_features))\n",
    "    features = num_features + cat_features\n",
    "\n",
    "    str2int_dict = {}\n",
    "    str2int_dict[\"EJ\"] = {\"A\": 1, \"B\": 0}\n",
    "    df_train[\"EJ\"] = df_train[\"EJ\"].map(str2int_dict[\"EJ\"])\n",
    "    \n",
    "    if config[\"denoise\"]:\n",
    "        df_train[num_features] = df_train[num_features].apply(lambda i: np.floor(i * 10))\n",
    "    \n",
    "    if config[\"scaler\"] == \"RobustScaler\":\n",
    "        scaler = StandardScaler()\n",
    "        df_train[num_features] = scaler.fit_transform(df_train[num_features])\n",
    "\n",
    "    os.makedirs(config[\"models_path\"], exist_ok=True)\n",
    "    shutil.copy(config_path, os.path.join(config[\"models_path\"], \"config.yaml\"))\n",
    "\n",
    "    gc.enable()\n",
    "\n",
    "    print(f\"\\nTraining {config['method']} model\")\n",
    "\n",
    "    fold_scores = []\n",
    "    oof_preds = np.zeros(len(df_train))\n",
    "    oof_fold = np.zeros(len(df_train))\n",
    "\n",
    "    kfold = MultilabelStratifiedKFold(**config[\"folds\"])\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(df_train, df_greeks.iloc[:, 1:-1])):\n",
    "        print(f\"\\nFold {fold + 1}\", flush=True)\n",
    "\n",
    "        x_train = df_train[features].iloc[train_idx]\n",
    "        y_train = df_train[\"Class\"].iloc[train_idx]\n",
    "        x_valid = df_train[features].iloc[valid_idx]\n",
    "        y_valid = df_train[\"Class\"].iloc[valid_idx]\n",
    "\n",
    "        if config[\"method\"] == \"catboost\":\n",
    "            model, valid_pred = train_catboost(\n",
    "                x_train, y_train, x_valid, y_valid, cat_features, config[\"model\"]\n",
    "            )\n",
    "        if config[\"method\"] == \"lightgbm\":\n",
    "            model, valid_pred = train_lightgbm(\n",
    "                x_train, y_train, x_valid, y_valid, cat_features, config[\"model\"], config[\"train\"]\n",
    "            )\n",
    "        if config[\"method\"] == \"xgboost\":\n",
    "            model, valid_pred = train_xgboost(\n",
    "                x_train, y_train, x_valid, y_valid, cat_features, config[\"model\"], config[\"train\"]\n",
    "            )\n",
    "\n",
    "        oof_preds[valid_idx] = valid_pred\n",
    "        oof_fold[valid_idx] = fold + 1\n",
    "\n",
    "        fold_scores.append(balanced_log_loss(y_valid, valid_pred))\n",
    "        print(f\"Fold {fold+1} OOF CV: {fold_scores[-1]:.4f}\")\n",
    "\n",
    "        with open(os.path.join(config[\"models_path\"], f\"model_f{fold + 1}.pkl\"), \"wb\") as file_obj:\n",
    "            pickle.dump(model, file_obj)\n",
    "\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"\")\n",
    "    for i in range(config[\"folds\"][\"n_splits\"]):\n",
    "        print(f\"Fold {i+1} {fold_scores[i]:.4f}\")\n",
    "    print(f\"mean/std: {np.mean(fold_scores):.4f}/{np.std(fold_scores):.4f}\")\n",
    "    score = balanced_log_loss(df_train[\"Class\"], oof_preds)\n",
    "    print(f\"OOF CV score is {score:.4f}\")\n",
    "\n",
    "    oof_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Id\": df_train[\"Id\"],\n",
    "            \"Class\": df_train[\"Class\"],\n",
    "            \"prediction\": oof_preds,\n",
    "            \"fold\": oof_fold,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    oof_df.to_csv(os.path.join(config[\"models_path\"], \"oof.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d773b65-f35c-4db5-88bd-181205dc9a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yaml\n",
      "{'data_path': '/home/trushin/Kaggle/icr-identify-age-related-conditions/',\n",
      " 'denoise': True,\n",
      " 'folds': {'n_splits': 10, 'random_state': 43, 'shuffle': True},\n",
      " 'method': 'catboost',\n",
      " 'model': {'auto_class_weights': 'Balanced',\n",
      "           'colsample_bylevel': 0.75,\n",
      "           'depth': 5,\n",
      "           'diffusion_temperature': 500,\n",
      "           'early_stopping_rounds': 20000,\n",
      "           'grow_policy': 'Depthwise',\n",
      "           'iterations': 500000,\n",
      "           'l2_leaf_reg': 3.0,\n",
      "           'langevin': True,\n",
      "           'learning_rate': 0.0006,\n",
      "           'min_data_in_leaf': 56,\n",
      "           'random_seed': 42,\n",
      "           'random_strength': 10.0,\n",
      "           'subsample': 0.8,\n",
      "           'verbose': 10000},\n",
      " 'models_path': 'models',\n",
      " 'scaler': 'RobustScaler'}\n",
      "Original number of numerical features: 55\n",
      "Original number of categorical features: 1\n",
      "\n",
      "Training catboost model\n",
      "\n",
      "Fold 1\n",
      "0:\tlearn: 0.6930981\ttest: 0.6930481\tbest: 0.6930481 (0)\ttotal: 47.2ms\tremaining: 6h 33m 8s\n",
      "10000:\tlearn: 0.3250408\ttest: 0.3378673\tbest: 0.3378673 (10000)\ttotal: 6.22s\tremaining: 5m 4s\n",
      "20000:\tlearn: 0.0909231\ttest: 0.1707376\tbest: 0.1707376 (20000)\ttotal: 12.7s\tremaining: 5m 4s\n",
      "30000:\tlearn: 0.0104094\ttest: 0.1126415\tbest: 0.1123322 (27864)\ttotal: 19s\tremaining: 4m 57s\n",
      "40000:\tlearn: 0.0043347\ttest: 0.1104935\tbest: 0.1101908 (32093)\ttotal: 24.6s\tremaining: 4m 42s\n",
      "50000:\tlearn: 0.0029434\ttest: 0.1208188\tbest: 0.1101908 (32093)\ttotal: 30.1s\tremaining: 4m 31s\n",
      "Stopped by overfitting detector  (20000 iterations wait)\n",
      "\n",
      "bestTest = 0.1101908464\n",
      "bestIteration = 32093\n",
      "\n",
      "Shrink model to first 32094 iterations.\n",
      "Fold 1 OOF CV: 0.1102\n",
      "\n",
      "Fold 2\n",
      "0:\tlearn: 0.6931191\ttest: 0.6930915\tbest: 0.6930915 (0)\ttotal: 636us\tremaining: 5m 18s\n",
      "10000:\tlearn: 0.3232120\ttest: 0.3627096\tbest: 0.3627096 (10000)\ttotal: 6.17s\tremaining: 5m 2s\n",
      "20000:\tlearn: 0.0873699\ttest: 0.2229870\tbest: 0.2229870 (20000)\ttotal: 12.8s\tremaining: 5m 6s\n",
      "30000:\tlearn: 0.0095930\ttest: 0.1944648\tbest: 0.1901660 (25375)\ttotal: 19s\tremaining: 4m 57s\n",
      "40000:\tlearn: 0.0037632\ttest: 0.2055456\tbest: 0.1901660 (25375)\ttotal: 24.8s\tremaining: 4m 45s\n",
      "Stopped by overfitting detector  (20000 iterations wait)\n",
      "\n",
      "bestTest = 0.1901659561\n",
      "bestIteration = 25375\n",
      "\n",
      "Shrink model to first 25376 iterations.\n",
      "Fold 2 OOF CV: 0.1902\n",
      "\n",
      "Fold 3\n",
      "0:\tlearn: 0.6929532\ttest: 0.6929187\tbest: 0.6929187 (0)\ttotal: 702us\tremaining: 5m 51s\n",
      "10000:\tlearn: 0.3107794\ttest: 0.4276498\tbest: 0.4276446 (9999)\ttotal: 6.3s\tremaining: 5m 8s\n",
      "20000:\tlearn: 0.0876067\ttest: 0.2610275\tbest: 0.2610256 (19999)\ttotal: 12.9s\tremaining: 5m 9s\n",
      "30000:\tlearn: 0.0098441\ttest: 0.1775721\tbest: 0.1772753 (29795)\ttotal: 19.3s\tremaining: 5m 2s\n",
      "40000:\tlearn: 0.0039521\ttest: 0.1751464\tbest: 0.1740212 (36391)\ttotal: 25.2s\tremaining: 4m 50s\n",
      "50000:\tlearn: 0.0027057\ttest: 0.1799258\tbest: 0.1740212 (36391)\ttotal: 31s\tremaining: 4m 38s\n",
      "Stopped by overfitting detector  (20000 iterations wait)\n",
      "\n",
      "bestTest = 0.1740211647\n",
      "bestIteration = 36391\n",
      "\n",
      "Shrink model to first 36392 iterations.\n",
      "Fold 3 OOF CV: 0.1740\n",
      "\n",
      "Fold 4\n",
      "0:\tlearn: 0.6929455\ttest: 0.6930053\tbest: 0.6930053 (0)\ttotal: 734us\tremaining: 6m 7s\n",
      "10000:\tlearn: 0.3193719\ttest: 0.3778245\tbest: 0.3778245 (10000)\ttotal: 6.54s\tremaining: 5m 20s\n",
      "20000:\tlearn: 0.0897753\ttest: 0.1959024\tbest: 0.1959024 (20000)\ttotal: 13.6s\tremaining: 5m 25s\n",
      "30000:\tlearn: 0.0100941\ttest: 0.1208407\tbest: 0.1208344 (29997)\ttotal: 20.3s\tremaining: 5m 18s\n",
      "40000:\tlearn: 0.0038510\ttest: 0.0984631\tbest: 0.0984599 (39977)\ttotal: 26.6s\tremaining: 5m 5s\n",
      "50000:\tlearn: 0.0023487\ttest: 0.0840558\tbest: 0.0840558 (50000)\ttotal: 32.9s\tremaining: 4m 56s\n"
     ]
    }
   ],
   "source": [
    "run_training(\"config.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
